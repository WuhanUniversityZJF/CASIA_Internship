Institute of Automation, Chinese Academy of Sciences  
07/2024-09/2024  
Role: Research Assistant in Multimodal Large Language Models  
Supervisor: Assoc. Prof. Guibo Zhu  
	Built a multimodal knowledge-graph Q&A system by integrating locally deployed Llama3 via Ollama with Neo4j, enabling structured knowledge retrieval and generative question answering for complex scenarios  
	Created a Python virtual environment, integrated multimodal libraries and database drivers, and locally deployed Lenna and LLaVA models  
	Compared Lenna and LLaVA, quantitatively analyzing performance differences: Lenna's <DET> token improved detection accuracy (85.5% vs 70%), while LLaVA produced more fluent text generation  
	Investigated Lenna's core modules (MSQ feature alignment, <DET> token) and LLaVA's architectural innovations (Grounding-DINO fusion), leveraging the BLIP framework to identify potential improvements in image-text alignment and multi-task self-supervised pretraining  
	Expanded the Neo4j knowledge graph, incorporating Lenna, LLaVA, and BLIP models along with their tasks, dependencies, and performance data, and integrated with Llama3 for natural-language Q&A
